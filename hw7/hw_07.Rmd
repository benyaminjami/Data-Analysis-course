---
title: "Seventh Week: Generalized Linear Models"
subtitle: "Murder or suicide"
author: "benyamin jami al ahmadi 94105282"
date: "`r Sys.time()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

<div align="center">
<img  src="images/giraffe-suicide-fail-cartoon.jpg"  align = 'center'>
</div>

> <p dir="RTL"> 
با توجه به سوالات مرگ و میر در آمریکا به سوالات زیر پاسخ دهید.
</p>

```{r,warning=FALSE,message=FALSE,echo=FALSE}



library(h2o)
library(readr)
library(dplyr)
library(highcharter)
library(ggplot2)
library(corrplot)
library(boot)
library(car)
murder_suicide = read.csv("../data/murder_suicide.csv")
# Useful functions when working with logistic regression
library(data.table)
library(ROCR)
library(grid)
library(caret)
library(dplyr)
library(scales)
library(ggplot2)
library(gridExtra)
library(data.table)
library(tidyr)
# ------------------------------------------------------------------------------------------
# [AccuracyCutoffInfo] : 
# Obtain the accuracy on the trainining and testing dataset.
# for cutoff value ranging from .4 to .8 ( with a .05 increase )
# @train   : your data.table or data.frame type training data ( assumes you have the predicted score in it ).
# @test    : your data.table or data.frame type testing data
# @predict : prediction's column name (assumes the same for training and testing set)
# @actual  : actual results' column name
# returns  : 1. data : a data.table with three columns.
#            		   each row indicates the cutoff value and the accuracy for the 
#            		   train and test set respectively.
# 			 2. plot : plot that visualizes the data.table

AccuracyCutoffInfo <- function( train, test, predict, actual )
{
  # change the cutoff value's range as you please 
  cutoff <- seq( .4, .8, by = .05 )
  
  accuracy <- lapply( cutoff, function(c)
  {
    # use the confusionMatrix from the caret package
    cm_train <- ConfusionMatrixInfo(train, predict, actual, c)
    cm_test  <- ConfusionMatrixInfo(test, predict, actual, c)
    
    dt <- data.table( cutoff = c,
                      train  = cm_train$data %>% summarise(sum(type %in% c('TP', 'TN'))/nrow(.)),
                      test   = cm_test$data %>% summarise(sum(type %in% c('TP', 'TN'))/nrow(.)))
    colnames(dt) <- c('cutoff', 'train', 'test')
    return(dt)
  }) %>% rbindlist()
  
  # visualize the accuracy of the train and test set for different cutoff value 
  # accuracy in percentage.
  accuracy_long <- gather( accuracy, "data", "accuracy", -1 )
  
  plot <- ggplot( accuracy_long, aes( cutoff, accuracy, group = data, color = data ) ) + 
    geom_line( size = 1 ) + geom_point( size = 3 ) +
    scale_y_continuous( label = percent ) +
    ggtitle( "Train/Test Accuracy for Different Cutoff" )
  
  return( list( data = accuracy, plot = plot ) )
}


# ------------------------------------------------------------------------------------------
# [ConfusionMatrixInfo] : 
# Obtain the confusion matrix plot and data.table for a given
# dataset that already consists the predicted score and actual outcome.
# @data    : your data.table or data.frame type data that consists the column
#            of the predicted score and actual outcome 
# @predict : predicted score's column name
# @actual  : actual results' column name
# @cutoff  : cutoff value for the prediction score 
# return   : 1. data : a data.table consisting of three column
#            		   the first two stores the original value of the prediction and actual outcome from
#			 		   the passed in data frame, the third indicates the type, which is after choosing the 
#			 		   cutoff value, will this row be a true/false positive/ negative 
#            2. plot : plot that visualizes the data.table 

ConfusionMatrixInfo <- function( data, predict, actual, cutoff )
{	
  # extract the column ;
  # relevel making 1 appears on the more commonly seen position in 
  # a two by two confusion matrix	
  predict <- data[[predict]]
  actual  <- relevel( as.factor( data[[actual]] ), "1" )
  
  result <- data.table( actual = actual, predict = predict )
  
  # caculating each pred falls into which category for the confusion matrix
  result[ , type := ifelse( predict >= cutoff & actual == 1, "TP",
                            ifelse( predict >= cutoff & actual == 0, "FP", 
                                    ifelse( predict <  cutoff & actual == 1, "FN", "TN" ) ) ) %>% as.factor() ]
  
  # jittering : can spread the points along the x axis 
  plot <- ggplot( result, aes( actual, predict, color = type ) ) + 
    geom_violin( fill = "white", color = NA ) +
    geom_jitter( shape = 1 ) + 
    geom_hline( yintercept = cutoff, color = "blue", alpha = 0.6 ) + 
    scale_y_continuous( limits = c( 0, 1 ) ) + 
    scale_color_discrete( breaks = c( "TP", "FN", "FP", "TN" ) ) + # ordering of the legend 
    guides( col = guide_legend( nrow = 2 ) ) + # adjust the legend to have two rows  
    ggtitle( sprintf( "Confusion Matrix with Cutoff at %.2f", cutoff ) )
  
  return( list( data = result, plot = plot ) )
}


# ------------------------------------------------------------------------------------------
# [ROCInfo] : 
# Pass in the data that already consists the predicted score and actual outcome.
# to obtain the ROC curve 
# @data    : your data.table or data.frame type data that consists the column
#            of the predicted score and actual outcome
# @predict : predicted score's column name
# @actual  : actual results' column name
# @cost.fp : associated cost for a false positive 
# @cost.fn : associated cost for a false negative 
# return   : a list containing  
#			 1. plot        : a side by side roc and cost plot, title showing optimal cutoff value
# 				 	   		  title showing optimal cutoff, total cost, and area under the curve (auc)
# 		     2. cutoff      : optimal cutoff value according to the specified fp/fn cost 
#		     3. totalcost   : total cost according to the specified fp/fn cost
#			 4. auc 		: area under the curve
#		     5. sensitivity : TP / (TP + FN)
#		     6. specificity : TN / (FP + TN)

ROCInfo <- function( data, predict, actual, cost.fp, cost.fn )
{
  # calculate the values using the ROCR library
  # true positive, false postive 
  pred <- prediction( data[[predict]], data[[actual]] )
  perf <- performance( pred, "tpr", "fpr" )
  roc_dt <- data.frame( fpr = perf@x.values[[1]], tpr = perf@y.values[[1]] )
  
  # cost with the specified false positive and false negative cost 
  # false postive rate * number of negative instances * false positive cost + 
  # false negative rate * number of positive instances * false negative cost
  cost <- perf@x.values[[1]] * cost.fp * sum( data[[actual]] == 0 ) + 
    ( 1 - perf@y.values[[1]] ) * cost.fn * sum( data[[actual]] == 1 )
  
  cost_dt <- data.frame( cutoff = pred@cutoffs[[1]], cost = cost )
  
  # optimal cutoff value, and the corresponding true positive and false positive rate
  best_index  <- which.min(cost)
  best_cost   <- cost_dt[ best_index, "cost" ]
  best_tpr    <- roc_dt[ best_index, "tpr" ]
  best_fpr    <- roc_dt[ best_index, "fpr" ]
  best_cutoff <- pred@cutoffs[[1]][ best_index ]
  
  # area under the curve
  auc <- performance( pred, "auc" )@y.values[[1]]
  
  # normalize the cost to assign colors to 1
  normalize <- function(v) ( v - min(v) ) / diff( range(v) )
  
  # create color from a palette to assign to the 100 generated threshold between 0 ~ 1
  # then normalize each cost and assign colors to it, the higher the blacker
  # don't times it by 100, there will be 0 in the vector
  col_ramp <- colorRampPalette( c( "green", "orange", "red", "black" ) )(100)   
  col_by_cost <- col_ramp[ ceiling( normalize(cost) * 99 ) + 1 ]
  
  roc_plot <- ggplot( roc_dt, aes( fpr, tpr ) ) + 
    geom_line( color = rgb( 0, 0, 1, alpha = 0.3 ) ) +
    geom_point( color = col_by_cost, size = 4, alpha = 0.2 ) + 
    geom_segment( aes( x = 0, y = 0, xend = 1, yend = 1 ), alpha = 0.8, color = "royalblue" ) + 
    labs( title = "ROC", x = "False Postive Rate", y = "True Positive Rate" ) +
    geom_hline( yintercept = best_tpr, alpha = 0.8, linetype = "dashed", color = "steelblue4" ) +
    geom_vline( xintercept = best_fpr, alpha = 0.8, linetype = "dashed", color = "steelblue4" )				
  
  cost_plot <- ggplot( cost_dt, aes( cutoff, cost ) ) +
    geom_line( color = "blue", alpha = 0.5 ) +
    geom_point( color = col_by_cost, size = 4, alpha = 0.5 ) +
    ggtitle( "Cost" ) +
    scale_y_continuous( labels = comma ) +
    geom_vline( xintercept = best_cutoff, alpha = 0.8, linetype = "dashed", color = "steelblue4" )	
  
  # the main title for the two arranged plot
  sub_title <- sprintf( "Cutoff at %.2f - Total Cost = %f, AUC = %.3f", 
                        best_cutoff, best_cost, auc )
  
  # arranged into a side by side plot
  plot <- arrangeGrob( roc_plot, cost_plot, ncol = 2, 
                       top = textGrob( sub_title, gp = gpar( fontsize = 16, fontface = "bold" ) ) )
  
  return( list( plot 		  = plot, 
                cutoff 	  = best_cutoff, 
                totalcost   = best_cost, 
                auc         = auc,
                sensitivity = best_tpr, 
                specificity = 1 - best_fpr ) )
}


```


***

<p dir="RTL">
۱. از میان متغیرهای داده مرگ و میر یک زیرمجموعه ایی بدون حشو در نظر بگیرید.
ماتریس همبستگی متغیرهای مختلف را به دست آورده و سپس رسم نمایید. علاوه بر این نمودار پراکنش متغیرهای انتخاب شده را همزمان نسبت به هم رسم نمایید.
</p>
```{r,message=FALSE,warning=FALSE}
data1 = murder_suicide %>% filter(EducationReportingFlag == 1, AgeType == 1) %>% select(ResidentStatus,Education2003Revision,MonthOfDeath,Sex,Age,PlaceOfDeathAndDecedentsStatus,MaritalStatus,DayOfWeekOfDeath,MethodOfDisposition,ActivityCode,PlaceOfInjury,RaceRecode5,CauseRecode358,MannerOfDeath,MethodOfDisposition,PlaceOfInjury)
data1 %>% mutate_if(is.character, factor) %>% mutate_if(is.factor, as.numeric) -> data1
data1$MannerOfDeath <- ifelse(data1$MannerOfDeath==3,1,0)
data1 %>% select_if(is.numeric) %>% cor(use="complete.obs") %>% corrplot(tl.cex = 0.5,tl.col = "black")
data1 %>% filter(row_number() < 1000) %>% scatterplotMatrix(cex = 0.05)
```



***

<p dir="RTL">
۲. اثر هر یک از متغیرهای جنسیت، نژاد،آموزش، سن و نحوه تدفین را بر مرگ یا خودکشی ارزیابی کنید.
</p>
<p dir="RTL">
میتوان دید که در مه موارد با توجه به مقدار کم p-value فرض صفر رد میشود  و میتوان گفت که موثر میباشند.
</p>

```{r}
data1 %>% group_by(Sex,MannerOfDeath) %>% summarise(n = n()) %>% tidyr::spread(MannerOfDeath,n) %>% .[,-1] %>% as.matrix() %>% chisq.test()

data1 %>% group_by(RaceRecode5,MannerOfDeath) %>% summarise(n = n()) %>% tidyr::spread(MannerOfDeath,n) %>% .[,-1] %>% as.matrix() %>% chisq.test()

data1 %>% group_by(Education2003Revision,MannerOfDeath) %>% summarise(n = n()) %>% tidyr::spread(MannerOfDeath,n) %>% .[,-1] %>% as.matrix() %>% chisq.test()

data1 %>% mutate(MannerOfDeath = ifelse(MannerOfDeath == 2,0,1)) %>% glm(formula = MannerOfDeath~Age,family = binomial(link = 'logit')) %>% summary.glm()

data1 %>% group_by(MethodOfDisposition,MannerOfDeath) %>% summarise(n = n()) %>% tidyr::spread(MannerOfDeath,n) %>% .[,-1] %>% as.matrix() %>% chisq.test()

```

***

<p dir="RTL">
۳. با استفاده از مدل رگرسیون لاجستیک یک مدل به داده ها برازش دهید و سپس آن را نقص یابی کنید.
</p>
```{r}
model1<-glm(data = data1 %>% mutate(MannerOfDeath = as.factor(MannerOfDeath)),formula = MannerOfDeath ~ ., family = binomial(link = 'logit'))
summary.glm(model1)
data1[,-c(1,3,8)] -> data3
model2<-glm(data = data3 %>% mutate(MannerOfDeath = as.factor(MannerOfDeath)),formula = MannerOfDeath ~ ., family = binomial(link = 'logit'))
summary.glm(model2)
```


***

<p dir="RTL">
۴. با استفاده از سه نمودار خروجی مدل را نسبت به داده واقعی ارزیابی کنید.
</p>
```{r}
data3$fit <- predict(object = model2, data3,type = "response")
cm_info = ConfusionMatrixInfo(data = data3, predict = "fit",actual = "MannerOfDeath", cutoff = 0.5)
cm_info$plot

data3$pred <- ifelse(data3$fit>0.5,1,0)
table(data3$pred,data3$MannerOfDeath) %>% plot()
plot(model2)
```

***

<p dir="RTL">
۵. ابتدا ۲۰ درصد داده را به صورت تصادفی به عنوان تست در نظر بگیرید. مدل را با استفاده از ۸۰ درصد باقی مانده برازش دهید. با استفاده از پارامتر قطع ۰.۵ نتایج را برای داده تست پیش بینی کنید. سپس کمیت های زیر را محاسبه کنید.
</p>

* P: positive samples
* N: negative samples
* TP: true positive TP (eqv. with hit)
* TN: true negative (eqv. with correct rejection)
* FP: false positive (eqv. with false alarm, Type I error)
* FN: false negative (eqv. with miss, Type II error)
* Accuracy (ACC) ACC = (TP+TN)/(P+T)
* False positive rate (FPR): 1- TN/N
* True positive rate (TPR): TP/P

<p dir="RTL">
مشابه آنچه در کلاس گفته شد نمایشی از  چهار کمیت 
TN, TP,FP,FN
به همراه داده ها رسم نمایید.
</p>
```{r}
set.seed(100)  # setting seed to reproduce results of random sampling
trainingRowIndex <- sample(1:nrow(data3), 0.8*nrow(data3))  # row indices for training data
trainingData <- data3[trainingRowIndex, ]  # model training data
testData  <- data3[-trainingRowIndex, ]   # test data
testmodel <- glm(data = trainingData %>% mutate(MannerOfDeath = as.factor(MannerOfDeath)),formula = MannerOfDeath ~ ., family = binomial(link = 'logit'))
testData$fit <- predict(object = testmodel, testData,type = "response")
testData$pred <- ifelse(testData$fit > 0.5,1,0)
P = sum(testData$pred == 1)
P
N = sum(testData$pred == 0)
N
TP = sum(testData$pred == 1 & testData$MannerOfDeath == 1)
TP
TN = sum(testData$pred == 0 & testData$MannerOfDeath == 0)
TN
FP = sum(testData$pred == 1 & testData$MannerOfDeath == 0)
FP
FN = sum(testData$pred == 0 & testData$MannerOfDeath == 1)
FN
ACC <- (TP+TN)/(P+N)
ACC
FPR <- 1- TN/N
FPR
TPR<- TP/P
TPR
cm_info = ConfusionMatrixInfo(data = testData, predict = "fit",actual = "MannerOfDeath", cutoff = .5)

cm_info$plot
```

***

<p dir="RTL">
۶. نمودار صحت مدل (accuracy) را بر حسب مقادیر مختلف قطع برای داده تست رسم نمایید. کدام پارامتر قطع بالاترین صحت را در پیش بینی داراست؟
</p>
```{r}
trainingData$fit <- predict(object = testmodel, trainingData,type = "response")
trainingData$pred <- ifelse(trainingData$fit > 0.5,1,0)
accuracy_info = AccuracyCutoffInfo( train = trainingData, test = testData, 
                                     predict = "fit", actual = "MannerOfDeath" )
accuracy_info$plot
accs = c()
i = 0
maxacc = 0;
acc = 0
for(i in seq(0, to = 1, by = 0.001)){
  testData$pred <- ifelse(testData$fit > i,1,0)
  P = sum(testData$pred == 1)
  N = sum(testData$pred == 0)
  TP = sum(testData$pred == 1 & testData$MannerOfDeath == 1)
  TN = sum(testData$pred == 0 & testData$MannerOfDeath == 0)
  FP = sum(testData$pred == 1 & testData$MannerOfDeath == 0)
  FN = sum(testData$pred == 0 & testData$MannerOfDeath == 1)
  ACC <- (TP+TN)/(P+N)
  accs = c(accs,ACC)
  #print(paste("cut off: " , as.character(i) , " ACC:" , as.character(ACC)))
  if(ACC > maxacc){
    maxacc = ACC
    acc = i
  }
}
acc
maxacc
temp = data_frame(cutoff = seq(0,to=1,by=0.001),ACC = accs)
ggplot(temp) + geom_line(aes(x = cutoff,y=ACC),color = "blue")
```

***

<p dir="RTL">
۷. نمودار 
ROC
 را برای داده های قسمت قبل رسم نمایید. همچنین نقطه مربوط به بهترین پارامتر قطع را مشخص نمایید.
</p>
```{r}
cost_fp = 100;cost_fn = 100
roc_info = ROCInfo( data = cm_info$data, predict = "predict", 
                     actual = "actual", cost.fp = cost_fp, cost.fn = cost_fn )
grid.draw(roc_info$plot)
```

***

<p dir="RTL">
۸. با قرار دادن کمیت 
nfolds = 5
و با استفاده از 
H20
مدل مساله را بسازید و نتیجه حاصل را ارزیابی کنید.
</p>
```{r}
h2o.init()
data8 <- as.h2o(data3 %>% mutate(MannerOfDeath = as.factor(MannerOfDeath)))
model8 = h2o.glm(training_frame = data8,y = "MannerOfDeath",x = data3 %>% colnames() %>% .[-12],family = "binomial",nfold=5)
summary(model8)
```

<p dir="RTL"> 
با توجه به نتایج حداکثر دقت 0.943121 میباشد.
</p>

***

<p dir="RTL"> 
۹. آیا ما میتوانیم سرویسی به قضات ارایه کنیم تا با استفاده از اطلاعات مرگ بتوانند موارد مشکوک به قتل را از خودکشی تفکیک دهند؟
</p>
<p dir="RTL"> 
با توجه به اینه حداکثر دقت در این مدل0.943121میباشد میتوان گف که میتواند کمک خوبی در دادگاه دهد و در موارد خاص رای دادگاه را به حقیقت نزدیک تر کند اما نمیتوان به از این مدل به صورت کاملا مستقیم استفاده کرد.
</p>


